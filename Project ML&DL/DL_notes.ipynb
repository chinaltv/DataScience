{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前言\n",
    "进入深度学习后，因为使用的包不同，对待模型的原理不再是像sklearn一样简单创建一个xx器（预测器、预处理器……），再使用内置的方法，而是先构建使用包方法构建模型结构，再使用相应方法迭代训练。  \n",
    "所有的代码，为可重复性，都应该加入随机种子。参数具体是random_state = ...，为节省空间，下述不再写作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tqdm\n",
    "import sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 强化学习\n",
    "强化学习是深度学习里面非常特别的一类。很明显地，该数据科学方法引入了心理学行为主义/应用行为分析的思想，使用了“强化”、“奖励”等多个概念来对数据进行多轮次训练。如果说之前的数据科学（机器学习、批量学习）可以说还在建模的框架内，与科学研究中的“真理”推断只是稍微有些差异（稍微转向预测）；那么从强化学习开始，数据科学则走向了更严格的，纯粹为了目的服务的方向。  \n",
    "强化学习的核心思想是探索与利用（Exploration and Exploitation）。所谓的探索即是科研，即得到“真理”，建构对世界的认识，但不利于最后的结果产出（最大化收益）。商业上的ABtest其实就是随机对照试验RCT，属于科研精神的一环，而强化学习所强调的探索与利用的平衡，则是“算法精神”起作用，纯粹为了目的服务。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ϵ−贪心算法 Epsilon-Greedy Algorithm\n",
    "  \n",
    "# Define Action class\n",
    "class Actions:\n",
    "    def __init__(self, m):\n",
    "        self.m = m\n",
    "        self.mean = 0\n",
    "        self.N = 0\n",
    "\n",
    "    # Choose a random action\n",
    "    def choose(self): \n",
    "        return np.random.randn() + self.m\n",
    "\n",
    "    # Update the action-value estimate\n",
    "    def update(self, x):\n",
    "        self.N += 1\n",
    "        self.mean = (1 - 1.0 / self.N) * self.mean + 1.0 / self.N * x\n",
    "\n",
    "def run_experiment(m1, m2, m3, eps, N):\n",
    "    actions = [Actions(m1), Actions(m2), Actions(m3)]\n",
    "    data = np.empty(N)\n",
    "    for i in range(N):   # epsilon greedy\n",
    "        p = np.random.random()\n",
    "        if p < eps:\n",
    "            j = np.random.choice(3)\n",
    "        else:\n",
    "            j = np.argmax([a.mean for a in actions])\n",
    "        x = actions[j].choose()\n",
    "        actions[j].update(x)\n",
    "    \n",
    "    # for the plot\n",
    "    data[i] = x\n",
    "    cumulative_average = np.cumsum(data) / (np.arange(N) + 1)\n",
    "    \n",
    "    # plot moving average ctr\n",
    "    plt.plot(cumulative_average)\n",
    "    plt.plot(np.ones(N)*m1)\n",
    "    plt.plot(np.ones(N)*m2)\n",
    "    plt.plot(np.ones(N)*m3)\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    for a in actions:\n",
    "        print(a.mean)\n",
    "    return cumulative_average\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    c_1 = run_experiment(1.0, 2.0, 3.0, 0.1, 100000)\n",
    "    c_05 = run_experiment(1.0, 2.0, 3.0, 0.05, 100000)\n",
    "    c_01 = run_experiment(1.0, 2.0, 3.0, 0.01, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 置信区间上界算法\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# import the dataset\n",
    "dataset = pd.read_csv('Ads_CTR_Optimisation.csv')\n",
    "\n",
    "# Implementing UCB\n",
    "N = 10000\n",
    "d = 10\n",
    "ads_selected = []\n",
    "numbers_of_selections = [0] * d\n",
    "sums_of_rewards = [0] * d\n",
    "total_reward = 0\n",
    "for n in range(0, N):\n",
    "    ad = 0\n",
    "    max_upper_bound = 0\n",
    "    for i in range(0, d):\n",
    "        if numbers_of_selections[i] > 0:\n",
    "            average_reward = sums_of_rewards[i] / numbers_of_selections[i]\n",
    "            delta_i = math.sqrt(3/2 * math.log(n + 1) / numbers_of_selections[i])\n",
    "            upper_bound = average_reward + delta_i\n",
    "        else:\n",
    "            upper_bound = 1e400\n",
    "        if upper_bound > max_upper_bound:\n",
    "            max_upper_bound = upper_bound\n",
    "            ad = i\n",
    "    ads_selected.append(ad)\n",
    "    reward = dataset.values[n, ad]\n",
    "    numbers_of_selections[ad] = numbers_of_selections[ad] + 1\n",
    "    sums_of_rewards[ad] = sums_of_rewards[ad] + reward\n",
    "    total_reward = total_reward + reward\n",
    "\n",
    "# Visualising the results\n",
    "plt.hist(ads_selected)\n",
    "plt.title('Histogram of ads selections')\n",
    "plt.xlabel('Ads')\n",
    "plt.ylabel('Number of times each ad was selected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汤普森采样/伯努利-汤普森采样/高斯-汤普森采样/softmax-汤普森采样\n",
    "\n",
    "def thompson_sampling(env, \n",
    "                      alpha=1,\n",
    "                      beta=0,\n",
    "                      n_episodes=1000):\n",
    "    Q = np.zeros((env.action_space.n), dtype=np.float64)\n",
    "    N = np.zeros((env.action_space.n), dtype=np.int)\n",
    "    \n",
    "    Qe = np.empty((n_episodes, env.action_space.n), dtype=np.float64)\n",
    "    returns = np.empty(n_episodes, dtype=np.float64)\n",
    "    actions = np.empty(n_episodes, dtype=np.int)\n",
    "    name = 'Thompson Sampling {}, {}'.format(alpha, beta)\n",
    "    for e in tqdm(range(n_episodes), \n",
    "                  desc='Episodes for: ' + name, \n",
    "                  leave=False):\n",
    "        samples = np.random.normal(\n",
    "            loc=Q, scale=alpha/(np.sqrt(N) + beta))\n",
    "        action = np.argmax(samples)\n",
    "\n",
    "        _, reward, _, _ = env.step(action)\n",
    "        N[action] += 1\n",
    "        Q[action] = Q[action] + (reward - Q[action])/N[action]\n",
    "\n",
    "        Qe[e] = Q\n",
    "        returns[e] = reward\n",
    "        actions[e] = action\n",
    "    return name, returns, Qe, actions\n",
    "\n",
    "class GaussianThompsonSocket():   # 本部分类基于他人的代码，使用高斯汤普森类方法处理它自己的机器人代码对象。后续应把该串代码整理成函数形式。\n",
    "    def __init__(self, q):                \n",
    "                \n",
    "        self.τ_0 = 0.0001  # the posterior precision\n",
    "        self.μ_0 = 1       # the posterior mean\n",
    "        \n",
    "        # pass the true reward value to the base PowerSocket             \n",
    "        super().__init__(q)         \n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\" return a value from the the posterior normal distribution \"\"\"\n",
    "        return (np.random.randn() / np.sqrt(self.τ_0)) + self.μ_0    \n",
    "                    \n",
    "    def update(self,R):\n",
    "        \"\"\" update this socket after it has returned reward value 'R' \"\"\"   \n",
    "\n",
    "        # do a standard update of the estimated mean\n",
    "        super().update(R)    \n",
    "               \n",
    "        # update the mean and precision of the posterior\n",
    "        self.μ_0 = ((self.τ_0 * self.μ_0) + (self.n * self.Q))/(self.τ_0 + self.n)        \n",
    "        self.τ_0 += 1      \n",
    "\n",
    "    def charge(self):\n",
    "        \"\"\" return a random amount of charge \"\"\"\n",
    "        # the reward is a guassian distribution with unit variance around the true value 'q'\n",
    "        value = np.random.randn() + self.q \n",
    "\n",
    "def softmax(env, \n",
    "            init_temp=float('inf'), \n",
    "            min_temp=0.0,\n",
    "            decay_ratio=0.04,\n",
    "            n_episodes=1000):\n",
    "    Q = np.zeros((env.action_space.n), dtype=np.float64)\n",
    "    N = np.zeros((env.action_space.n), dtype=np.int)\n",
    "\n",
    "    Qe = np.empty((n_episodes, env.action_space.n), dtype=np.float64)\n",
    "    returns = np.empty(n_episodes, dtype=np.float64)\n",
    "    actions = np.empty(n_episodes, dtype=np.int)\n",
    "    name = 'Lin SoftMax {}, {}, {}'.format(init_temp, \n",
    "                                           min_temp,\n",
    "                                           decay_ratio)\n",
    "    # can't really use infinity\n",
    "    init_temp = min(init_temp,\n",
    "                    sys.float_info.max)\n",
    "    # can't really use zero\n",
    "    min_temp = max(min_temp,\n",
    "                   np.nextafter(np.float32(0), \n",
    "                                np.float32(1)))\n",
    "    for e in tqdm(range(n_episodes),\n",
    "                  desc='Episodes for: ' + name, \n",
    "                  leave=False):\n",
    "        decay_episodes = n_episodes * decay_ratio\n",
    "        temp = 1 - e / decay_episodes\n",
    "        temp *= init_temp - min_temp\n",
    "        temp += min_temp\n",
    "        temp = np.clip(temp, min_temp, init_temp)\n",
    "\n",
    "        scaled_Q = Q / temp\n",
    "        norm_Q = scaled_Q - np.max(scaled_Q)\n",
    "        exp_Q = np.exp(norm_Q)\n",
    "        probs = exp_Q / np.sum(exp_Q)\n",
    "        assert np.isclose(probs.sum(), 1.0)\n",
    "\n",
    "        action = np.random.choice(np.arange(len(probs)), \n",
    "                                  size=1, \n",
    "                                  p=probs)[0]\n",
    "\n",
    "        _, reward, _, _ = env.step(action)\n",
    "        N[action] += 1\n",
    "        Q[action] = Q[action] + (reward - Q[action])/N[action]\n",
    "        \n",
    "        Qe[e] = Q\n",
    "        returns[e] = reward\n",
    "        actions[e] = action\n",
    "    return name, returns, Qe, actions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习：基本PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary # torchsummary不支持lstm\n",
    "from torchinfo import summary as info_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判断当前计算平台"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前计算平台： cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "print('当前计算平台：', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【模型参数】\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128, 17]             --\n",
      "|    └─Conv1d: 2-1                       [-1, 64, 501]             3,200\n",
      "|    └─BatchNorm1d: 2-2                  [-1, 64, 501]             128\n",
      "|    └─ReLU: 2-3                         [-1, 64, 501]             --\n",
      "|    └─MaxPool1d: 2-4                    [-1, 64, 63]              --\n",
      "|    └─Dropout: 2-5                      [-1, 64, 63]              --\n",
      "|    └─Conv1d: 2-6                       [-1, 128, 64]             65,536\n",
      "|    └─BatchNorm1d: 2-7                  [-1, 128, 64]             256\n",
      "|    └─ReLU: 2-8                         [-1, 128, 64]             --\n",
      "|    └─Conv1d: 2-9                       [-1, 128, 65]             131,072\n",
      "|    └─BatchNorm1d: 2-10                 [-1, 128, 65]             256\n",
      "|    └─ReLU: 2-11                        [-1, 128, 65]             --\n",
      "|    └─Conv1d: 2-12                      [-1, 128, 66]             131,072\n",
      "|    └─BatchNorm1d: 2-13                 [-1, 128, 66]             256\n",
      "|    └─ReLU: 2-14                        [-1, 128, 66]             --\n",
      "|    └─MaxPool1d: 2-15                   [-1, 128, 17]             --\n",
      "├─Sequential: 1-2                        [-1, 128, 10]             --\n",
      "|    └─Conv1d: 2-16                      [-1, 64, 61]              25,600\n",
      "|    └─BatchNorm1d: 2-17                 [-1, 64, 61]              128\n",
      "|    └─ReLU: 2-18                        [-1, 64, 61]              --\n",
      "|    └─MaxPool1d: 2-19                   [-1, 64, 16]              --\n",
      "|    └─Dropout: 2-20                     [-1, 64, 16]              --\n",
      "|    └─Conv1d: 2-21                      [-1, 128, 17]             49,152\n",
      "|    └─BatchNorm1d: 2-22                 [-1, 128, 17]             256\n",
      "|    └─ReLU: 2-23                        [-1, 128, 17]             --\n",
      "|    └─Conv1d: 2-24                      [-1, 128, 18]             98,304\n",
      "|    └─BatchNorm1d: 2-25                 [-1, 128, 18]             256\n",
      "|    └─ReLU: 2-26                        [-1, 128, 18]             --\n",
      "|    └─Conv1d: 2-27                      [-1, 128, 19]             98,304\n",
      "|    └─BatchNorm1d: 2-28                 [-1, 128, 19]             256\n",
      "|    └─ReLU: 2-29                        [-1, 128, 19]             --\n",
      "|    └─MaxPool1d: 2-30                   [-1, 128, 10]             --\n",
      "├─Sequential: 1-3                        [-1, 6]                   --\n",
      "|    └─Dropout: 2-31                     [-1, 3456]                --\n",
      "|    └─Linear: 2-32                      [-1, 6]                   20,742\n",
      "==========================================================================================\n",
      "Total params: 624,774\n",
      "Trainable params: 624,774\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 29.65\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.04\n",
      "Params size (MB): 2.38\n",
      "Estimated Total Size (MB): 3.43\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):  # define the CNN architecture\n",
    "    def __init__(self, in_channel=1, small_Fs=8, big_Fs=6, Fs=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.smallCNN = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=Fs//2, stride =Fs//16, padding=Fs//2//2, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=8, stride=8,  padding=4),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=small_Fs,\n",
    "                      stride=1, padding=small_Fs//2, bias =False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=small_Fs,\n",
    "                      stride=1, padding=small_Fs//2, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=small_Fs,\n",
    "                      stride=1, padding=small_Fs//2, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4, padding=2)\n",
    "        )\n",
    "\n",
    "        self.bigCNN = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=Fs*4, stride=Fs//2, padding=Fs*4//2, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=4, stride=4, padding=2),  # padding = filter_size//2\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=big_Fs, stride=1, padding=big_Fs//2, bias= False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=big_Fs, stride=1, padding=big_Fs//2, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv1d(in_channels =128, out_channels=128, kernel_size=big_Fs, stride=1, padding=big_Fs//2, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1280 + 2176, 6)  # big and small conv concat\n",
    "            # 貌似和输入数据长度有关，1280+2176适用于长度3000，若要改为长度7500，需修改此处\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        small = self.smallCNN(x)\n",
    "        big = self.bigCNN(x)\n",
    "\n",
    "        feature_big = torch.flatten(big, 1)\n",
    "        feature_small = torch.flatten(small, 1)  # (batch, channel)\n",
    "        output = torch.cat((feature_big, feature_small), dim=1)\n",
    "        output = self.fc(output)\n",
    "        return(output)\n",
    "\n",
    "\n",
    "# 配置模型并配置在当前计算平台\n",
    "model = MyModel()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # 使用 CrossEntropy 作为 Cost 函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=[0.9, 0.999])  # 使用基础Adam作为Optimizier（优化器）\n",
    "\n",
    "print('【模型参数】')\n",
    "summary(model,(1,3000))\n",
    "\n",
    "epochs = 100  # 重复次数为 100\n",
    "cnt = 0  # 用于判断early stopping\n",
    "\n",
    "# 训练和验证的loss（损失）值\n",
    "train_loss = torch.zeros(epochs)\n",
    "val_loss = torch.zeros(epochs)\n",
    "\n",
    "# 训练和验证的acc（准确度）值\n",
    "train_acc = torch.zeros(epochs)\n",
    "val_acc = torch.zeros(epochs)\n",
    "\n",
    "# 初始loss是无穷大\n",
    "valid_loss_min = np.Inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 保存一个原始模型，做测试用\n",
    "trans_model = model\n",
    "save_model_path = \"./model_best.pt\"\n",
    "### 导入需要的模型\n",
    "save_model = torch.load(save_model_path)\n",
    "\n",
    "### 设定要删除的key\n",
    "all_keys = ['smallCNN.0.weight', 'smallCNN.1.weight', 'smallCNN.1.bias', 'smallCNN.1.running_mean', 'smallCNN.1.running_var', 'smallCNN.1.num_batches_tracked', 'smallCNN.5.weight', 'smallCNN.6.weight', 'smallCNN.6.bias', 'smallCNN.6.running_mean', 'smallCNN.6.running_var', 'smallCNN.6.num_batches_tracked', 'smallCNN.8.weight', 'smallCNN.9.weight', 'smallCNN.9.bias', 'smallCNN.9.running_mean', 'smallCNN.9.running_var', 'smallCNN.9.num_batches_tracked', 'smallCNN.11.weight', 'smallCNN.12.weight', 'smallCNN.12.bias', 'smallCNN.12.running_mean', 'smallCNN.12.running_var', 'smallCNN.12.num_batches_tracked', 'bigCNN.0.weight', 'bigCNN.1.weight', 'bigCNN.1.bias', 'bigCNN.1.running_mean', 'bigCNN.1.running_var', 'bigCNN.1.num_batches_tracked', 'bigCNN.5.weight', 'bigCNN.6.weight', 'bigCNN.6.bias', 'bigCNN.6.running_mean', 'bigCNN.6.running_var', 'bigCNN.6.num_batches_tracked', 'bigCNN.8.weight', 'bigCNN.9.weight', 'bigCNN.9.bias', 'bigCNN.9.running_mean', 'bigCNN.9.running_var', 'bigCNN.9.num_batches_tracked', 'bigCNN.11.weight', 'bigCNN.12.weight', 'bigCNN.12.bias', 'bigCNN.12.running_mean', 'bigCNN.12.running_var', 'bigCNN.12.num_batches_tracked','fc.1.weight', 'fc.1.bias']\n",
    "freeze_keys = ['smallCNN.0.weight', 'smallCNN.1.weight', 'smallCNN.1.bias', 'smallCNN.1.running_mean', 'smallCNN.1.running_var', 'smallCNN.1.num_batches_tracked', 'smallCNN.5.weight', 'smallCNN.6.weight', 'smallCNN.6.bias', 'smallCNN.6.running_mean', 'smallCNN.6.running_var', 'smallCNN.6.num_batches_tracked', 'smallCNN.8.weight', 'smallCNN.9.weight', 'smallCNN.9.bias', 'smallCNN.9.running_mean', 'smallCNN.9.running_var', 'smallCNN.9.num_batches_tracked', 'smallCNN.11.weight', 'smallCNN.12.weight', 'smallCNN.12.bias', 'smallCNN.12.running_mean', 'smallCNN.12.running_var', 'smallCNN.12.num_batches_tracked', 'bigCNN.0.weight', 'bigCNN.1.weight', 'bigCNN.1.bias', 'bigCNN.1.running_mean', 'bigCNN.1.running_var', 'bigCNN.1.num_batches_tracked', 'bigCNN.5.weight', 'bigCNN.6.weight', 'bigCNN.6.bias', 'bigCNN.6.running_mean', 'bigCNN.6.running_var', 'bigCNN.6.num_batches_tracked', 'bigCNN.8.weight', 'bigCNN.9.weight', 'bigCNN.9.bias', 'bigCNN.9.running_mean', 'bigCNN.9.running_var', 'bigCNN.9.num_batches_tracked', 'bigCNN.11.weight', 'bigCNN.12.weight', 'bigCNN.12.bias', 'bigCNN.12.running_mean', 'bigCNN.12.running_var', 'bigCNN.12.num_batches_tracked']\n",
    "delete_keys = list(set(all_keys).difference(set(freeze_keys)))\n",
    "\n",
    "### 传入参数\n",
    "for para in delete_keys:\n",
    "    del save_model[para]\n",
    "trans_model_dict = trans_model.state_dict()\n",
    "state_dict = {k:v for k,v in save_model.items() if k in trans_model_dict.keys()}\n",
    "trans_model_dict.update(state_dict)\n",
    "trans_model.load_state_dict(trans_model_dict)\n",
    "\n",
    "### 冻结参数\n",
    "for name, parameter in trans_model.named_parameters():\n",
    "    for key in freeze_keys:\n",
    "        if key in name:\n",
    "            parameter.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 暂时无用的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单个切片的目标长度\n",
    "len_slice = 3000\n",
    "\n",
    "# 单个切片的有效数据长度\n",
    "len_slice_useful = 2800\n",
    "\n",
    "# 单侧补零长度\n",
    "len_slice_addzeros_oneside = int((len_slice - len_slice_useful)/2)\n",
    "\n",
    "# 单侧补零模板\n",
    "zeros_oneside = [0.5]*len_slice_addzeros_oneside\n",
    "\n",
    "# 各分期的数据文件保存位置，以及迁移学习的best_model_path\n",
    "path_W = 'E:/SleepEEGNet/DeepSleepNet_SM/data_SM/W'\n",
    "path_L = 'E:/SleepEEGNet/DeepSleepNet_SM/data_SM/L'\n",
    "path_D = 'E:/SleepEEGNet/DeepSleepNet_SM/data_SM/D'\n",
    "path_R = 'E:/SleepEEGNet/DeepSleepNet_SM/data_SM/R'\n",
    "save_model_path = 'E:/SleepEEGNet/DeepSleepNet_SM/sample/model_best.pt'\n",
    "\n",
    "# 各分期的EEG文件列表\n",
    "datalist_W = glob.glob(path_W + '/**')\n",
    "datalist_L = glob.glob(path_L + '/**')\n",
    "datalist_D = glob.glob(path_D + '/**')\n",
    "datalist_R = glob.glob(path_R + '/**')\n",
    "\n",
    "# 各分期的切片数量\n",
    "num_W = len(datalist_W)\n",
    "num_L = len(datalist_L)\n",
    "num_D = len(datalist_D)\n",
    "num_R = len(datalist_R)\n",
    "num_all = num_W + num_L + num_D + num_R\n",
    "\n",
    "# 将各分期EEG数据归一化、前后补零，然后分类汇总（拼接）\n",
    "data_W = []\n",
    "for idx in range(num_W):\n",
    "    current_data = np.loadtxt(datalist_W[idx], dtype=np.float32, delimiter=',')\n",
    "    current_data = current_data[:len_slice_useful]\n",
    "\n",
    "    # 数据归一化\n",
    "    current_data = (current_data - np.min(current_data)) / (np.max(current_data) - np.min(current_data))\n",
    "\n",
    "    # 数据切片前后补零\n",
    "    current_data = np.array(zeros_oneside + list(current_data) + zeros_oneside)\n",
    "    data_W.append(current_data)\n",
    "\n",
    "data_L = []\n",
    "for idx in range(num_L):\n",
    "    current_data = np.loadtxt(datalist_L[idx], dtype=np.float32, delimiter=',')\n",
    "    current_data = current_data[:len_slice_useful]\n",
    "\n",
    "    # 数据归一化\n",
    "    current_data = (current_data - np.min(current_data)) / (np.max(current_data) - np.min(current_data))\n",
    "\n",
    "    # 数据切片前后补零\n",
    "    current_data = np.array(zeros_oneside + list(current_data) + zeros_oneside)\n",
    "    data_L.append(current_data)\n",
    "\n",
    "data_D = []\n",
    "for idx in range(num_D):\n",
    "    current_data = np.loadtxt(datalist_D[idx], dtype=np.float32, delimiter=',')\n",
    "    current_data = current_data[:len_slice_useful]\n",
    "\n",
    "    # 数据归一化\n",
    "    current_data = (current_data - np.min(current_data)) / (np.max(current_data) - np.min(current_data))\n",
    "\n",
    "    # 数据切片前后补零\n",
    "    current_data = np.array(zeros_oneside + list(current_data) + zeros_oneside)\n",
    "\n",
    "    data_D.append(current_data)\n",
    "\n",
    "data_R = []\n",
    "for idx in range(num_R):\n",
    "    current_data = np.loadtxt(datalist_R[idx], dtype=np.float32, delimiter=',')\n",
    "    current_data = current_data[:len_slice_useful]\n",
    "\n",
    "    # 数据归一化\n",
    "    current_data = (current_data - np.min(current_data)) / (np.max(current_data) - np.min(current_data))\n",
    "\n",
    "    # 数据切片前后补零\n",
    "    current_data = np.array(zeros_oneside + list(current_data) + zeros_oneside)\n",
    "\n",
    "    data_R.append(current_data)\n",
    "\n",
    "data_all = data_W + data_L + data_D + data_R\n",
    "\n",
    "# 预生成各分期的标签（与EEG采样点对齐）：0-清醒（W），1-浅睡（L），2-深睡（D），3-REM（R）\n",
    "label_W = [0] * num_W\n",
    "label_L = [1] * num_L\n",
    "label_D = [2] * num_D\n",
    "label_R = [3] * num_R\n",
    "label_all = np.array(label_W + label_L + label_D + label_R)\n",
    "\n",
    "# 验证集占总数据集的比例\n",
    "percentage_validation = 0.2\n",
    "\n",
    "# 训练集、验证集的切片数量\n",
    "num_validation = int(np.floor(num_all * percentage_validation))\n",
    "num_train = num_all - num_validation\n",
    "\n",
    "# 打乱顺序，抽取验证集/训练集（数据+标签）\n",
    "idx_all = np.arange(num_all)\n",
    "np.random.shuffle(idx_all)\n",
    "idx_validation = idx_all[:num_validation]\n",
    "idx_train = idx_all[num_validation:]\n",
    "\n",
    "data_train = []\n",
    "label_train = []\n",
    "for jj in idx_train:\n",
    "    data_train.append(data_all[jj])\n",
    "    label_train.append(label_all[jj])\n",
    "\n",
    "data_validation = []\n",
    "label_validation = []\n",
    "for ii in idx_validation:\n",
    "    data_validation.append(data_all[ii])\n",
    "    label_validation.append(label_all[ii])\n",
    "\n",
    "# 保存验证集/训练集数据（二进制）\n",
    "np.savez('data_label_train', data_train=data_train, label_train=label_train)\n",
    "np.savez('data_label_validation', data_validation=data_validation, label_validation=label_validation)\n",
    "\n",
    "print('##### 数眠 DeepSleepNet 深度学习 #####')\n",
    "print('【切片总数】')\n",
    "print('清醒期：', num_W)\n",
    "print('浅睡期：', num_L)\n",
    "print('深睡期：', num_D)\n",
    "print('REM期：', num_R)\n",
    "print('【训练集 vs 验证集】')\n",
    "print('验证集占比：', percentage_validation*100, '%')\n",
    "print('训练集：', num_train)\n",
    "print('验证集：', num_validation)\n",
    "\n",
    "# 画5个示例切片\n",
    "plt.figure\n",
    "for idx in range(1, 5+1):\n",
    "    plt.subplot(5, 1, idx)\n",
    "    plt.plot(data_train[idx])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始模型训练\n",
    "print(\"===== Start Learning =====\")\n",
    "for epoch in range(epochs):\n",
    "    trans_model.train()  # 切换为model训练模式\n",
    "    sums = 0\n",
    "\n",
    "    # 模型训练\n",
    "    for ii in range(num_train):\n",
    "\n",
    "        inputs = np.array(data_train[ii])\n",
    "        labels = [label_train[ii]]\n",
    "\n",
    "        # inputs = inputs.reshape(-1, 1, len_slice)\n",
    "        inputs = inputs.reshape(-1, 1, len_slice)\n",
    "\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # 初始化 optimizer - >初始化所有梯度\n",
    "        logits = trans_model(inputs)  # logits是模型预测的值\n",
    "        loss = criterion(logits, labels)  # 通过先前定义的cost函数计算loss\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss[epoch] += loss.item()  # 训练过程的loss累加\n",
    "\n",
    "        ps = F.softmax(logits, dim=1)  # 将logits归一化，赋给ps\n",
    "        top_p, top_class = ps.topk(1, dim=1)  # 求出ps的最大值top_p及其索引top_class\n",
    "        equals = top_class == labels.reshape(top_class.shape)   # 寻找正确分类项\n",
    "\n",
    "        train_acc[epoch] += torch.mean(equals.type(torch.FloatTensor)).item()  # 计算训练过程的准确度\n",
    "\n",
    "        sums += 1\n",
    "\n",
    "    # 求整个训练过程中loss和acc的平均值\n",
    "    train_loss[epoch] /= sums\n",
    "    train_acc[epoch] /= sums\n",
    "\n",
    "    # 模型验证\n",
    "    val_sums = 0\n",
    "    trans_model.eval()  # 切换为model验证模式\n",
    "\n",
    "    with torch.no_grad():  # 张量的计算过程中无需计算梯度\n",
    "\n",
    "        for jj in range(num_validation):\n",
    "\n",
    "            inputs = data_validation[jj]\n",
    "            labels = [label_validation[jj]]\n",
    "\n",
    "            inputs = inputs.reshape(-1, 1, len_slice)\n",
    "\n",
    "            inputs = torch.tensor(inputs, dtype=torch.float)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 计算预测值\n",
    "            logits = trans_model(inputs)  # logits是模型预测的值\n",
    "            val_single_loss = criterion(logits, labels)  # 通过先前定义的cost函数计算loss\n",
    "\n",
    "            val_loss[epoch] += val_single_loss.item()  # 验证过程的loss累加\n",
    "\n",
    "            # 计算准确度\n",
    "            ps = F.softmax(logits, dim=1)  # 将logits归一化，赋给ps\n",
    "            top_p, top_class = ps.topk(1, dim=1)  # 求出ps的最大值top_p及其索引top_class\n",
    "\n",
    "            equals = top_class == labels.view(*top_class.shape)  # 寻找正确分类项\n",
    "            val_acc[epoch] += torch.mean(equals.type(torch.FloatTensor)).item()  # 计算验证过程的准确度\n",
    "\n",
    "            val_sums += 1\n",
    "\n",
    "        # 求整个验证过程中loss和acc的平均值\n",
    "        val_loss[epoch] /= val_sums\n",
    "        val_acc[epoch] /= val_sums\n",
    "\n",
    "    # PRINT LOSS & ACC\n",
    "    print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "          f\"Train loss: {train_loss[epoch]:.3f}.. \"\n",
    "          f\"Train acc: {train_acc[epoch]:.3f}.. \"\n",
    "          f\"val loss: {val_loss[epoch]:.3f}.. \"\n",
    "          f\"val accuracy: {val_acc[epoch]:.3f}\")\n",
    "\n",
    "    #  保存最佳模型\n",
    "    if val_loss[epoch] <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min, val_loss[epoch]))\n",
    "        torch.save(trans_model.state_dict(), 'Trans_model_best.pt')\n",
    "        valid_loss_min = val_loss[epoch]\n",
    "\n",
    "        # 初始化“远端停止”计数（如果存在最低 Loss 值）\n",
    "        cnt = 0\n",
    "\n",
    "    # 如果 Loss 改进超过 30 次，则退出\n",
    "    #  Early Stopping\n",
    "    if cnt >= 30:\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "\n",
    "    cnt += 1  # Loss 改进失败"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
